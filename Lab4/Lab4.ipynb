{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4.ipynb",
      "provenance": [],
      "mount_file_id": "1yFMKuIQITkVEfLD32Au5v9VF1m5JpDgG",
      "authorship_tag": "ABX9TyPnjuyUs2Cp2AXCW/vglbbu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patryktk/175IC-machine-learning-21176/blob/main/Lab4/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCwD1mJlVKKy"
      },
      "source": [
        "from openpyxl import Workbook\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "wb = Workbook()\n",
        "gielda = wb.create_sheet(\"\")\n",
        "gielda.title = \"Giełda\"\n",
        "linki = wb.create_sheet(\"\")\n",
        "linki.title = \"Linki\"\n",
        "filmweb = wb.create_sheet(\"\")\n",
        "filmweb.title = \"FilmWeb\"\n",
        "\n",
        "response = requests.get(\"https://stooq.pl/q/?s=cdr\")\n",
        "html_doc = response.text\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "kurs_cdp = soup.find(id=\"f13\").string\n",
        "print(kurs_cdp)\n",
        "procentowa_dnia_cdp = soup.find(id=\"aq_cdr_m3\").string\n",
        "liczba_transakcji = soup.find(id=\"aq_cdr_n1\").string\n",
        "\n",
        "\n",
        "gielda['A1'] = 'Kurs'\n",
        "gielda['B1'] = kurs_cdp\n",
        "gielda['A2'] = 'Zmiana'\n",
        "gielda['B2'] = procentowa_dnia_cdp\n",
        "gielda['A3'] = 'Liczba transakcji'\n",
        "gielda['B3'] = liczba_transakcji\n",
        "\n",
        "wb.save('tkaczyk-175ic.xlsx')\n",
        "\n",
        "#Powyższy skrypt pokazuje jak zapisać dane z stooq.pl do excela bazując na akcjach \"cdr\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSA2NZOlN9QS"
      },
      "source": [
        "from random import randint\n",
        "from openpyxl import Workbook\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "wb = Workbook()\n",
        "gielda = wb.create_sheet(\"\")\n",
        "gielda.title = \"Giełda\"\n",
        "linki = wb.create_sheet(\"\")\n",
        "linki.title = \"Linki\"\n",
        "filmweb = wb.create_sheet(\"\")\n",
        "filmweb.title = \"FilmWeb\"\n",
        "\n",
        "\n",
        "gielda['A1'] = 'Kurs'\n",
        "gielda['A2'] = 'Zmiana'\n",
        "gielda['A3'] = 'Liczba transakcji'\n",
        "nazwa = \"\"\n",
        "ilosc_poprawnych = 1\n",
        "kolumna  = 66\n",
        "while ilosc_poprawnych < 6:\n",
        "  nazwa = \"\"\n",
        "  for x in range(3):\n",
        "    nazwa = nazwa + chr(randint(97,122))\n",
        "  response = requests.get(\"https://stooq.pl/q/?s=\" + nazwa)\n",
        "  html_doc = response.text\n",
        "  soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "  sprawdzenie = soup.find(id=\"f18\").string\n",
        "  if(sprawdzenie == 'Wyszukiwanie symbolu'):\n",
        "    print(nazwa + \"-\")\n",
        "  else:\n",
        "    print(nazwa + \"+\")\n",
        "    # print(soup.find(id=\"aq_\"+ nazwa +\"_c1\").string)\n",
        "    # kurs_cdp = soup.find(id=\"aq_\"+ nazwa +\"_c1\").string\n",
        "    # procentowa_dnia_cdp = soup.find(id=\"aq_\"+ nazwa +\"_m3\").string\n",
        "    # liczba_transakcji = soup.find(id=\"aq_\"+ nazwa +\"_n1\").string\n",
        "    # gielda[chr(kolumna) + '1'] = kurs_cdp\n",
        "    # gielda[chr(kolumna) + '2'] = procentowa_dnia_cdp\n",
        "    # gielda[chr(kolumna) + '3'] = liczba_transakcji\n",
        "    # kolumna = kolumna + 1 \n",
        "    ilosc_poprawnych = ilosc_poprawnych + 1\n",
        "    print(ilosc_poprawnych)\n",
        "  \n",
        "\n",
        "print(\"Done\")\n",
        "print(ilosc_poprawnych)\n",
        "wb.save('tkaczyk-175ic.xlsx')\n",
        "#Powyższy skrypt pokazuje jak przebiega losowanie nazw 3 członowych kodów, do spółek do wyszukiwania na stronie stooq.pl. A następnie scrapping na ów spółkach.\n",
        "#Ale pojawił się problem taki, za każdym razem komórka z danymi ma inne id, więc nie mogę zlokalizowac odpowidniej, przykład wyżej działa tylko dla spółki \"cdr\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnj2OIRYqQo9"
      },
      "source": [
        "from random import randint\n",
        "from openpyxl import Workbook\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"https://www.whitepress.pl/baza-wiedzy/51/jak-zaczac-pozyskiwac-linki-do-nowej-strony\")\n",
        "html_doc = response.text\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "\n",
        "r=1\n",
        "for a in soup.find_all('a', href=True):\n",
        "    linki.cell(row=r, column=1).hyperlink =  a['href']\n",
        "    r = r+1\n",
        "wb.save('tkaczyk-175ic.xlsx')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi4upvwJoO2g"
      },
      "source": [
        "#Filmweb\n",
        "response = requests.get(\"https://www.filmweb.pl/film/Joker-2019-810167\")\n",
        "html_doc = response.text\n",
        "soup = BeautifulSoup(html_doc,'html.parser')\n",
        "rezyser = soup.find(itemprop =\"director\").text\n",
        "data_premiery = soup.find('div', attrs={'class':'filmInfo__info'}).next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.next_sibling.text\n",
        "boxoffice = soup.find('div', attrs={'class':'boxoffice'}).previous_element\n",
        "ocena_filmu = soup.find('span', attrs={'class':'filmRating__rateValue'}).text\n",
        "\n",
        "filmweb['A1'] = 'Reżyser'\n",
        "filmweb['B1'] = rezyser\n",
        "filmweb['A2'] = 'Data Premiery'\n",
        "filmweb['B2'] = data_premiery\n",
        "filmweb['A3'] = 'BoxOffice'\n",
        "filmweb['B3'] = boxoffice\n",
        "filmweb['A4'] = 'Ocena filmu'\n",
        "filmweb['B4'] = ocena_filmu\n",
        "\n",
        "wb.save('tkaczyk-175ic.xlsx')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}