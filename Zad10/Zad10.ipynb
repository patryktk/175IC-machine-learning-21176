{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zad10.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYrqRO2jbVEDbo4TVQqdm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patryktk/175IC-machine-learning-21176/blob/main/Zad10/Zad10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB8mMwD1x5y0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import preprocessing\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation\r\n",
        "from keras.optimizers import SGD\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS0KueIrxP4E"
      },
      "source": [
        "def to_category(df_raw):\r\n",
        "    for key in df_raw.keys():\r\n",
        "        if df_raw[key].dtype == \"object\":\r\n",
        "            df_raw[key] = df_raw[key].astype(\"category\")\r\n",
        "    return df_raw\r\n",
        "\r\n",
        "def data_target_split(df):\r\n",
        "    data = df.copy()\r\n",
        "    target = data.pop('charges')\r\n",
        "\r\n",
        "    return data, target\r\n",
        "\r\n",
        "def scale(df, min_max_scaler):  \r\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\r\n",
        "    x_scaled = min_max_scaler.fit_transform(df)\r\n",
        "    min_max_scaler\r\n",
        "    df = pd.DataFrame(x_scaled)\r\n",
        "\r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "def custom_scale(df, normalize_tab=normalize_data_tab, target=False):\r\n",
        "    if target == False:\r\n",
        "        for i, key in enumerate(['age', 'bmi', 'children']):\r\n",
        "            df[key] = (df[key] - normalize_tab[i*2+1]) / (normalize_tab[i*2] - normalize_tab[i*2+1])\r\n",
        "\r\n",
        "    \r\n",
        "    else:\r\n",
        "        df = (df - normalize_tab[1]) / (normalize_tab[0] - normalize_tab[1])\r\n",
        "    \r\n",
        "    return df\r\n",
        "\r\n",
        "def normalized_to_real(x, normalize_tab=normalize_target_tab):\r\n",
        "    return x* (normalize_tab[0]-normalize_tab[1]) + normalize_tab[1]\r\n",
        "\r\n",
        "df_raw = pd.read_csv(\"https://storage.googleapis.com/esmartdata-courses-files/ml-course/insurance.csv\")\r\n",
        "\r\n",
        "\r\n",
        "print(df_raw[:10])\r\n",
        "\r\n",
        "\r\n",
        "df = df_raw.copy()\r\n",
        "\r\n",
        "df = to_category(df)\r\n",
        "\r\n",
        "df = pd.get_dummies(df, drop_first=True)\r\n",
        "\r\n",
        "data, target = data_target_split(df)\r\n",
        "\r\n",
        "normalize_data_tab = np.array([data['age'].max(), data['age'].min(), \r\n",
        "                               data['bmi'].max(), data['bmi'].min(), \r\n",
        "                               data['children'].max(), data['children'].min()])\r\n",
        "normalize_target_tab = np.array([target.max(), target.min()])\r\n",
        "\r\n",
        "data = custom_scale(data)\r\n",
        "target = custom_scale(target, normalize_target_tab, True)\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)\r\n",
        "\r\n",
        "X_train = np.array(X_train)\r\n",
        "X_test = np.array(X_test)\r\n",
        "y_train = np.array(y_train)\r\n",
        "y_test = np.array(y_test)\r\n",
        "\r\n",
        "print(f\"X_train: {X_train.shape}\")\r\n",
        "print(f\"y_train: {y_train.shape}\")\r\n",
        "print(f\"X_test: {X_test.shape}\")\r\n",
        "print(f\"y_test: {y_test.shape}\")\r\n",
        "\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(10, activation='relu', input_shape=(8,)))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(3, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='msle')\r\n",
        "hist = model.fit(X_train, y_train, batch_size=10, epochs=50, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}